# Assessing streetscape quality related to pedestrian crashes using self-supervised learning

**URSP688Y Project**<br>
**Spring 2025**<br>

**Author**<br>
Huan Zhou<br>
[hzhou715@umd.edu](hzhou715@umd.edu)

**Instructor**<br>
Chester Harvey<br>
National Center for Smart Growth<br>
[cwharvey@umd.edu](cwharvey@umd.edu)

##### 1. Question 

The project aims to develop a self-supervised learning model to assess streetscape quality related to pedestrian crashes. The project wants to assess the streetscape quality at a large scale based on street view images. Self-supervised learning in the project refers to use unlabeled or persudo-labeled data to pretrain the model, and then use labeled data (ground truth) to finetune the model.

##### 2. Data and Methods   

The data includes 1200 Baltimore Cityâ€™s street view images, which are download from Google Maps Platform using API.

The dataset is split as the train, validation, and test dataset. The train and validation dataset may total 1,100 Baltimore street view images (generated by ChatGPT, persudo-labeled images), with a ratio of 9:1 for training and validation. The test data contains 100 street view images (manually annotated), which have ground truth.

The methods include four key steps: street view images collection, labeling, self-supervised learning training, and evaluation.


## Related File
Please read "exercise04_huan.ipynb", which explains the methods in detail.




